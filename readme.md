# mini neural network

- is just a learning project
- i do it for fun
- inspired from this : [Youtube video](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=1)

## Done or todo

### Computation

- [x] Backpropagation.
- [x] Forward in a graph.s

### Dense & Model

- [ ] Basic model
- [x] Sequential
- [x] Dense (FCC)
- [ ] Convolution Layer (FCC)

### Activation

- [x] Tanh
- [-] ReLU & Variants
  - [x] ReLU
  - [ ] swish
  - [ ] LReLU
  - [ ] PReLU
  - [ ] ELU
  - [ ] SELU
- [x] Sigmoid.
- [x] Softmax.

### Gradient

- [x] Get graph (topo order)
- [x] Backward propagation
- [x] Grad reset
- [x] Gradient clipping
- [-] Gradient noize injection.
- [ ] More things on gradient ...

### Math

#### Reduce Ops

- [x] sum
- [x] mean
- [ ] add reduce on axis.

#### Elementwise ops

- [x] Add
- [x] Sub
- [x] Mul
- [x] Div
- [x] Pow (float exp)
- [x] Pow (Tensor exp)

#### Losses

- [x] MSE
- [x] MAE
- [-] BCE : bugged asf
- [ ] CCE

### Optimizer

- [x] SGD
- [x] Adam
- [ ] Adagrad
