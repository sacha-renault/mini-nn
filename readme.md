# mini neural network

- is just a learning project
- i do it for fun
- inspired from this : [Youtube video](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=1)

## Done or todo

### Computation
- [x] Backpropagation.
- [ ] Forward in a graph (instead of current impl where it has to run though all layers)

### Dense & Model
- [ ] Basic model
- [x] Sequential
- [x] Dense (FCC)
- [ ] Convolution Layer (FCC)

### Activation
- [ ] Remake activation behavior (it sucks rn).
- [x] Tanh
- [x] ReLU
- [x] Sigmoid
- [ ] Softmax (currently broken).

### Gradient
- [x] Get graph (topo order)
- [x] Backward propagation
- [x] Grad reset
- [ ] gradient clipping
- [ ]

### Math

#### Reduce Ops
- [x] sum
- [x] mean

#### Elementwise ops
- [ ] Add
- [ ] Sub
- [ ] Mul
- [ ] Div
- [x] Pow (float exp)
- [ ] Pow (Tensor exp)


### Optimizer
- [ ] Learn optimizer!!!
